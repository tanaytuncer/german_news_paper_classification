{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS-F5 Analysis of Big Data \n",
    "### German news article classification\n",
    "\n",
    "Author: Tanay Tunçer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "#Data preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from python.text_preprocessing import extract_nouns, remove_stopwords, drop_rows, stemming_text, split_data, remove_stopwords_punct\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "#Data visualization\n",
    "from python.data_visualization import bar_chart, histogram, get_top_n_gram, confusion_matrix_plot\n",
    "import plotly_express as px\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, GaussianNB\n",
    "\n",
    "#Quality metrics\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "#!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/input/raw/\"\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\"csv\"):\n",
    "        news_df = pd.read_csv(path + file)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_duplicates = news_df[\"text\"].duplicated().sum()\n",
    "print(f\"{n_duplicates} duplicates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = drop_rows(news_df, \"text\", news_df.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_data_preprocessing = False\n",
    "\n",
    "if start_data_preprocessing:\n",
    "    \"\"\"\n",
    "    If start_data_preprocessing == True then \n",
    "\n",
    "        1) For corpus_s1 start step 1, 3, 2 and 4.\n",
    "        2) For corpus_s2 start step 1,2, 5 and 6.\n",
    "        3) For corpus_ start step 1, 2 and 5\n",
    "    \n",
    "    For testing purposes use line 12 and 13.\n",
    "\n",
    "    Else if start_data_preprocessing == False then\n",
    "        Pre-processed data is loaded.\n",
    "    \"\"\"\n",
    "    corpus_s1 = news_df[:10].copy()\n",
    "    corpus_s2 = news_df[:10].copy()\n",
    "\n",
    "    #corpus_s1 = news_df.copy()\n",
    "    #corpus_s2 = news_df.copy()\n",
    "\n",
    "    print(\"Data preprocessing is started ..\")    \n",
    "    corpus_s1[\"text\"] = corpus_s1[\"text\"].map(lambda x: x.lower())\n",
    "    print(\"Step 1 is finished\") \n",
    "\n",
    "    corpus_s1[\"text\"] = corpus_s1[\"text\"].map(lambda x: RegexpTokenizer(r\"\\w+\").tokenize(x))\n",
    "    print(\"Step 2 is finished\") \n",
    "\n",
    "    #corpus_s1[\"text\"] = corpus_s1[\"text\"].apply(lambda x: stemming_text(x))\n",
    "    #print(\"Step 3 is finished\")      \n",
    "\n",
    "    #corpus_s1[\"text\"] = corpus_s1[\"text\"].apply(lambda x: remove_stopwords_punct(x))\n",
    "    #print(\"Step 4 is finished\")      \n",
    "\n",
    "    corpus_s2[\"text\"] = corpus_s1[\"text\"].map(lambda x: remove_stopwords(x))\n",
    "    print(\"Step 5 is finished\")    \n",
    "\n",
    "    corpus_s2[\"noun\"] = corpus_s2[\"text\"].apply(lambda x: extract_nouns(x))\n",
    "    print(\"Step 6 is finished\")   \n",
    "else: \n",
    "    corpus_s1 = pd.read_csv(\"data/input/clean/corpus_s1.csv\")\n",
    "    corpus_s2 = pd.read_csv(\"data/input/clean/corpus_s2.csv\")\n",
    "    corpus_ = pd.read_csv(\"data/input/clean/corpus_.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_summary = pd.DataFrame(news_df[\"variable\"].value_counts().reset_index())\n",
    "descriptive_summary[\"distribution\"] =  np.round((descriptive_summary[\"count\"] / descriptive_summary[\"count\"].sum()) *100,2) \n",
    "\n",
    "bar_chart(\n",
    "    x = descriptive_summary[\"count\"], \n",
    "    y = descriptive_summary[\"variable\"], \n",
    "    title = \"Anzahl der Nachrichtenartikel je Klasse\", \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart(\n",
    "    x = descriptive_summary[\"distribution\"], \n",
    "    y = descriptive_summary[\"variable\"], \n",
    "    title = \"Proz. Verteilung der Nachrichtenartikel je Klasse\", \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[\"word_count\"] = news_df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "histogram(news_df, \"word_count\", 100, \"Anzahl der Wörter in einem Artikel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = news_df[\"variable\"].unique()\n",
    "\n",
    "for class_name in class_names: \n",
    "    histogram(news_df[news_df[\"variable\"] == class_name], \"word_count\", 100, f\"Anzahl der Wörter in einem Artikel der Kategorie {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_ngram(df, class_name, n_min = 2, n_max = 3, top_n = 10):\n",
    "\n",
    "    filtered_df = df[df[\"variable\"] == class_name]\n",
    "    n_grams = get_top_n_gram(filtered_df[\"text\"],  n_words = top_n, n_min = n_min, n_max = n_max)\n",
    "    top_n_grams = pd.DataFrame(n_grams, columns = [\"n_gram\", \"count\"])\n",
    "\n",
    "    bar_chart(top_n_grams[\"count\"], top_n_grams[\"n_gram\"], f\"Top {top_n} Wörter der Kategorie {class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in class_names:\n",
    "    plot_top_ngram(corpus_s1, class_name, top_n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[\"word_count\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in class_names:\n",
    "    print(class_name)\n",
    "    print(news_df[news_df[\"variable\"] == class_name][\"word_count\"].describe())\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = get_top_n_gram(news_df[\"text\"],  n_words = 15, n_min = 2, n_max = 3)\n",
    "top_n_grams = pd.DataFrame(n_grams, columns = [\"n_gram\", \"count\"])\n",
    "\n",
    "bar_chart(top_n_grams[\"count\"], top_n_grams[\"n_gram\"], f\"Top 15 Wörter im Korpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(df, class_name, top = 10):\n",
    "    \n",
    "    filtered_df = df[df[\"variable\"] == class_name]\n",
    "    top_words = pd.Series(' '.join(filtered_df[\"text\"]).split()).value_counts()[:top]\n",
    "    top_words = pd.DataFrame(top_words, columns = [\"count\"]).reset_index().rename(columns = {\"index\":\"word\"})\n",
    "\n",
    "    bar_chart(x = top_words[\"count\"], y = top_words[\"word\"], title = f\"Top {top} Wörter der Kategorie {class_name}\")\n",
    "\n",
    "    return top_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in class_names:\n",
    "    plot_top_words(corpus_, class_name, top = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Similarity Matrix\n",
    "\n",
    "#filtered_corpus = corpus_s1[corpus_s1[\"text\"].apply(lambda x: len(x.split()) >= 200 and len(x.split()) <= 399)]\n",
    "\n",
    "articles = corpus_s1[\"text\"]\n",
    "class_names = corpus_s1[\"variable\"]\n",
    "class_name = class_names.unique()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=False)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(articles)\n",
    "\n",
    "mean_cosine_similarity = pd.DataFrame(index=class_name, columns=class_name)\n",
    "\n",
    "for t in tqdm(range(100)):\n",
    "    for i, class1 in enumerate(class_name): \n",
    "        for j, class2 in enumerate(class_name):\n",
    "\n",
    "            mask1 = (class_names == class1)\n",
    "            mask2 = (class_names == class2)\n",
    "        \n",
    "            similarity_matrix = cosine_similarity(tfidf_matrix[mask1], tfidf_matrix[mask2])\n",
    "            \n",
    "            mean_cosine_similarity.loc[class1, class2] = similarity_matrix[i, j].mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(mean_cosine_similarity, range_color= [-1,1], width=1000, height = 1000, color_continuous_scale=[\"red\", \"grey\", \"blue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow_s1, y_bow_s1, X_train_bow_s1, X_val_bow_s1, X_test_bow_s1, y_train_bow_s1, y_val_bow_s1, y_test_bow_s1 = split_data(corpus_s1[\"text\"], corpus_s1[\"variable\"], emb = True, imbalanced = False)\n",
    "\n",
    "baseline_v1 = GaussianNB()\n",
    "baseline_v1.fit(X_train_bow_s1, y_train_bow_s1)\n",
    "\n",
    "y_pred = baseline_v1.predict(X_test_bow_s1)\n",
    "f1 = np.round(f1_score(y_test_bow_s1, y_pred, average=\"weighted\"), 3)\n",
    "\n",
    "print(f\"Baseline model with f1 score of {f1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidfv1_s1, y_tfidfv1_s1, X_train_tfidfv1_s1, X_val_tfidfv1_s1, X_test_tfidfv1_s1, y_train_tfidfv1_s1, y_val_tfidfv1_s1, y_test_tfidfv1_s1 = split_data(corpus_s1[\"text\"], corpus_s1[\"variable\"], emb = False, imbalanced = False)\n",
    "\n",
    "baseline_v2 = GaussianNB()\n",
    "baseline_v2.fit(X_train_tfidfv1_s1, y_train_tfidfv1_s1)\n",
    "\n",
    "y_pred = baseline_v2.predict(X_test_tfidfv1_s1)\n",
    "f1 = np.round(f1_score(y_test_tfidfv1_s1, y_pred, average=\"weighted\"), 3)\n",
    "\n",
    "print(f\"Baseline model with f1 score of {f1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow_s2, y_bow_s2, X_train_bow_s2, X_val_bow_s2, X_test_bow_s2, y_train_bow_s2, y_val_bow_s2, y_test_bow_s2 = split_data(corpus_s2[\"noun\"], corpus_s2[\"variable\"], emb = True, imbalanced = False)\n",
    "\n",
    "baseline_v3 = GaussianNB()\n",
    "baseline_v3.fit(X_train_bow_s2, y_train_bow_s2)\n",
    "\n",
    "y_pred = baseline_v3.predict(X_test_bow_s2)\n",
    "f1 = np.round(f1_score(y_test_bow_s2, y_pred, average=\"weighted\"), 3)\n",
    "\n",
    "print(f\"Baseline model with f1 score of {f1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidfv1_s2, y_tfidfv1_s2, X_train_tfidfv1_s2, X_val_tfidfv1_s2, X_test_tfidfv1_s2, y_train_tfidfv1_s2, y_val_tfidfv1_s2, y_test_tfidfv1_s2 = split_data(corpus_s2[\"noun\"], corpus_s2[\"variable\"], emb = False, imbalanced = False)\n",
    "\n",
    "baseline_v4 = GaussianNB()\n",
    "baseline_v4.fit(X_train_tfidfv1_s2, y_train_tfidfv1_s2)\n",
    "\n",
    "y_pred = baseline_v4.predict(X_test_tfidfv1_s2)\n",
    "f1 = np.round(f1_score(y_test_tfidfv1_s2, y_pred, average=\"weighted\"), 3)\n",
    "\n",
    "print(f\"Baseline model with f1 score of{f1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidfv2_s1, y_tfidfv2_s1, X_train_tfidfv2_s1, X_val_tfidfv2_s1, X_test_tfidfv2_s1, y_train_tfidfv2_s1, y_val_tfidfv2_s1, y_test_tfidfv2_s1 = split_data(corpus_s1[\"text\"], corpus_s1[\"variable\"], emb = False, imbalanced = True)\n",
    "\n",
    "baseline_v5 = GaussianNB()\n",
    "baseline_v5.fit(X_train_tfidfv2_s1, y_train_tfidfv2_s1)\n",
    "\n",
    "y_pred = baseline_v5.predict(X_test_tfidfv2_s1)\n",
    "f1 = np.round(f1_score(y_test_tfidfv2_s1, y_pred, average = \"weighted\"), 3)\n",
    "\n",
    "print(f\"Baseline model with f1 score of {f1}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gnb_parameter = {\"var_smoothing\": [1e-10, 1e-06, 1e-1, .1, .33, .66, 1]}\n",
    "\n",
    "gnb_results = np.zeros((len(gnb_parameter[\"var_smoothing\"]), 3))\n",
    "\n",
    "n_iter = 0\n",
    "for var_smoothing in gnb_parameter[\"var_smoothing\"]:\n",
    "\n",
    "    gnb = GaussianNB(var_smoothing = var_smoothing)\n",
    "    gnb.fit(X_tfidfv2_s1, y_tfidfv2_s1)\n",
    "\n",
    "    y_val_pred = gnb.predict(X_val_tfidfv2_s1)\n",
    "    gnb_f1 = np.round(f1_score(y_val_tfidfv2_s1, y_val_pred, average=\"weighted\"), 3)\n",
    "\n",
    "    gnb_results[n_iter] = [n_iter, var_smoothing, gnb_f1]\n",
    "\n",
    "    n_iter += 1\n",
    "\n",
    "    print(f\"Model {n_iter}: with f1-score of {gnb_f1} is complemted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter_idx = np.argmax(gnb_results[:,2])\n",
    "best_parameter_value = gnb_results[best_parameter_idx,1]\n",
    "\n",
    "gnb = GaussianNB(var_smoothing = best_parameter_value)\n",
    "gnb.fit(X_tfidfv2_s1, y_tfidfv2_s1)\n",
    "\n",
    "y_pred = gnb.predict(X_test_tfidfv2_s1)\n",
    "print(np.round(f1_score(y_test_tfidfv2_s1, y_pred, average=\"weighted\"), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_tfidfv2_s1, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_plot(y_test_tfidfv2_s1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinominal Naive Bayes\n",
    "\n",
    "mnb_parameter = {\"alpha\": [1e-10, 1e-06, 1e-1, .1, .33, .66, 1]}\n",
    "mnb_results = np.zeros((len(mnb_parameter[\"alpha\"]), 3))\n",
    "\n",
    "n_iter = 0\n",
    "\n",
    "for alpha in mnb_parameter[\"alpha\"]:\n",
    "\n",
    "    mnb = MultinomialNB(alpha = alpha, fit_prior = True)\n",
    "    mnb.fit(X_tfidfv2_s1, y_tfidfv2_s1)\n",
    "\n",
    "    y_val_pred = mnb.predict(X_val_tfidfv2_s1)\n",
    "    mnb_f1 = np.round(f1_score(y_val_tfidfv2_s1, y_val_pred, average = \"weighted\"), 3)\n",
    "\n",
    "    mnb_results[n_iter] = [n_iter, alpha, mnb_f1]\n",
    "    n_iter += 1\n",
    "\n",
    "    print(f\"Model {n_iter} with F1-score of {mnb_f1} is completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter_idx = np.argmax(mnb_results[:,2])\n",
    "best_parameter_value = mnb_results[best_parameter_idx,1]\n",
    "\n",
    "mnb = MultinomialNB(alpha = best_parameter_value, fit_prior = True)\n",
    "mnb.fit(X_tfidfv2_s1, y_tfidfv2_s1)\n",
    "\n",
    "y_pred = mnb.predict(X_test_tfidfv2_s1)\n",
    "print(np.round(f1_score(y_test_tfidfv2_s1, y_pred, average=\"weighted\"), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_tfidfv2_s1, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_plot(y_test_tfidfv2_s1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete Naive Bayes\n",
    "\n",
    "cnb_parameter = {\"alpha\": [1e-10, 1e-06, 1e-1, .1, .33, .66, 1]} \n",
    "cnb_results = np.zeros((len(cnb_parameter[\"alpha\"]), 3))\n",
    "\n",
    "n_iter = 0\n",
    "for alpha in cnb_parameter[\"alpha\"]:\n",
    "\n",
    "    cnb = ComplementNB(alpha = alpha, norm = False)\n",
    "    cnb.fit(X_tfidfv1_s1, y_tfidfv1_s1)\n",
    "\n",
    "    y_val_pred = cnb.predict(X_val_tfidfv1_s1)\n",
    "    cnb_f1 = np.round(f1_score(y_val_tfidfv1_s1, y_val_pred, average=\"weighted\"), 3)\n",
    "\n",
    "    cnb_results[n_iter] = [n_iter, alpha, cnb_f1]\n",
    "    n_iter += 1\n",
    "\n",
    "    print(f\"Model {n_iter} with f1 score of {cnb_f1} is completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter_idx = np.argmax(cnb_results[:,2])\n",
    "best_parameter_value = cnb_results[best_parameter_idx,1]\n",
    "\n",
    "cnb = ComplementNB(alpha = best_parameter_value, norm = False)\n",
    "cnb.fit(X_tfidfv1_s1, y_tfidfv1_s1)\n",
    "\n",
    "y_pred = cnb.predict(X_test_tfidfv1_s1)\n",
    "print(np.round(f1_score(y_test_tfidfv1_s1, y_pred, average=\"weighted\"), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_tfidfv1_s1, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_plot(y_test_tfidfv1_s1, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
